---
layout: ../../layouts/MarkdownPostLayout.astro
title: 'Thoughts: Will we still need to know stuff?'
pubDate: 2023-06-17
description: 'With language models emerging, do I still need to learn how to program?'
author: 'Stanislaw Kalinowski'
color: 'F1C550'
---
With the existence of language models, I've been seeing people question the need for learning. Learning how to program, write, etc. And while I believe learning & knowledge will still be important, it is going to change.

There was a similar argument about learning when it came to the invention of writing,Socrates argued against writing believing it would make people lazy. He was correct in that we memorize less things now, but we still remember stuff! We just memorize what needs to be remembered. With language models, as they begin to do more informational work, we we will learn what needs to be learned.

So, what does need to be learned? 

Well the usefulness of information & knowledge won't go away with language models. And even if the models could take care of 90%, heck 99% of knowledge tasks, knowledge will still be useful.

→Knowledge helps us use & unlock the models.

→Knowledge helps us learned what to want.

→Knowledge helps us cover up for the model.

## Knowledge helps us use & unlock the models

Knowledge lets us unlock and better use the models. The outputs of the model are less constraint when we have a better understanding. So imagine if you ask it to explain some topic in chemistry. To someone more familiar with chemistry, it can be free to use the technical terms and give clearer example that demonstrate the concept, it doesn't have to shy away from jargon. But for a novice like me, I would need basic language and simpler terms, and any examples or analogies would have to be basic. By being more informed, we free the model to generate better outputs.

Knowledge also helps us unlock the model through our instructions. With an understanding of a subject we can better establish our desired output and improve the phrasing our question. Knowledge also gives us the ability to more precisely correct the model when it generates anything wrong.

Currently, even for normal tasks, their abilities are a bit lacking and when I use GPT4 to program, it can give me good starting points and suggestions, but needs carrying for the rest of it. There is a "last mile" problem with language models. Having the ability to correct this "last mile" is extremely useful and can save more time over re-prompting and wrangling the model, which involves clearing up your intentions. But you already know what you want, and you can just rework this last part.

## Knowledge helps us learn what to want

The language models will be put to do informational work for us, but we still need to decide what we want them to do. Being informed helps us make decisions on what to use the model for.

## Knowledge helps us cover up for the model

I think this is the most important part, similar to how we offload memory to paper and devices, we will offload knowledge work to models. Therefore, what we will learn is how to use the models to do work and what the models lack in their work.

Currently, the most prevalent lacking part is the out of scope generation, or in other terms, they struggle with areas outside of their training data. Sure, they can ideate and generate to create new suggestions, maybe even make a discovery, but its still an open question if they can generate new knowledge. I have a sense it won't remain this way, but as long as this remains the case, then it will up to be us to explore and contribute new information for the models.

The other lacking part, and the type of knowledge we will need to learn, is in solving the "last mile problem". Where language models, even currently, can give a pretty good generation, their abilities and interpretations are a bit lacking, and the output usually requires a few touch ups. We will learn enough to correct and fix the generation of models. Like right now, when I get GPT4 to write some code for me, it can give a decent generation or suggestions, but I find myself using it as a starting point and adjusting it to my needs. This ability to correct is important, because specifying and capturing all our intentions is the hard task of communication, but with the ability to correct, we only need the model to generate good enough, and quickly fix the "last mile".

## Conclusion

Therefore I think that being informed and knowledge is still important, even if the models will be taking care of 90% of the job. Knowledge helps us unlock the models. Allowing for better usage of the models, better specification, and for better use of the output through modifying & correcting it.

I want to end with a bit of a diverge, and discuss why knowing things is important because of one factor, knowledge is compounding. There is a great book called Proust & the Squid by Maryanne Wolf. It's about how children learn and acquire the ability to read. I liked their description of this learning process. Initially kids struggle and trudge through the text, they just don't know the words. But, suddenly, once they pass some threshold of knowledge, they acquire the ability to read. They can fill in the blanks for the words they don't know through the context. 

In my mind, knowledge works like this, it's a compounding process, the more we know, the easier it become to know more.