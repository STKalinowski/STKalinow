[{"content":"What\u0026rsquo;s the point in memorization if we can look things up, what\u0026rsquo;s the point of learning if a model can do it for us. With LLMs, I\u0026rsquo;ve seen people questioning the need for writing, programming, and learning in general. But, knowledge and skills are still useful and will be useful in the future, it\u0026rsquo;s just the emphasis and needs will change.\nSocrates argued against writing, believing it would make people lazy. He was correct, it made us lazy, but wrong about it being a bad thing. It\u0026rsquo;s good that I don\u0026rsquo;t have to remember random things I need once in a while. We memorize what needs to be remembered. Using a library for a small project, I\u0026rsquo;m just gonna look things up in the docs. Using pytorch constantly for my projects, it\u0026rsquo;s best I learn and commit it to memory. This is how it should be, learn what\u0026rsquo;s needed. Writing, phones, LLMs, they just changing the definition of what\u0026rsquo;s needed.\nRegardless, learning, memory, and intelligence is important. Even though we don\u0026rsquo;t have to do rote memorization right now, it\u0026rsquo;s important to know and understand concepts. You use concepts to understand and make decisions. New technology doesn\u0026rsquo;t change this fact. The reason intelligence matters is because part of intelligence is the usage of technology.\nKnowledge itself is a compounding thing. The more you know, the more you can learn. It has a thresh-holding effect.\nIn Proust and the Squid by Maryanne Wolf, there was a great passage describing how kids learn to read. At first they struggle with each word, but once they accumulate enough knowledge, then suddenly at once they get the ability to read. It\u0026rsquo;s a thresh-hold, they acquire enough knowledge about the surrounding words to infer on words they don\u0026rsquo;t know.I believe the same principle applies to knowledge in general, the more you know, the more you are able to infer and grasp other ideas.\nBetter understanding and knowledge serves as ways to unlock technology, especially LLMs.\nFor LLMs, knowing more lets you use the models better.\nYou can better communicate your desires, think about the levels an experience programmer can ask to write a program versus someone with no experience.\nYou can better use the output. You can take the output and tweak it, or ask to correct it. As well as the model has more room to explain. Imagine explaining something to a child versus an adult, we have more words and analogies to use for the adult than the child.\nBrass tax, learning is still important, it lets you make better decisions and use tools better. Skills like programming, writing, analysis, etc, aren\u0026rsquo;t going away. But they will change! So don\u0026rsquo;t give up learning, just be open to the changes coming.\n","permalink":"https://www.stkalinow.xyz/posts/knowledgeuseful/","summary":"What\u0026rsquo;s the point in memorization if we can look things up, what\u0026rsquo;s the point of learning if a model can do it for us. With LLMs, I\u0026rsquo;ve seen people questioning the need for writing, programming, and learning in general. But, knowledge and skills are still useful and will be useful in the future, it\u0026rsquo;s just the emphasis and needs will change.\nSocrates argued against writing, believing it would make people lazy.","title":"Thoughts: Do I still need to know stuff?"},{"content":"I\u0026rsquo;ve played league for a while, and one particular post on the league subreddit has resonated with me. This post was a translation for a discussion Dopa had on stream after reaching rank one.He discusses his idea of concepts, really just breaking down the game into a set of facts, whoever has the best facts wins. You don\u0026rsquo;t own them, you can take other peoples concepts and refine them.\nI think about this post from time to time. And I figured I\u0026rsquo;d share my most valuable concept:\nCompress and simplify your knowledge as much as possible.\nCompression of knowledge plays a role in all of retrieval, generalization, and simplification. The most elegant solutions are simple.\nThe idea that compression is intelligence has been floating around, at least in the circle of ML.\nI read about generalization from this post. It\u0026rsquo;s looking at the grokking effect and generalization. Looking at models on a spectrum between memorizing the solution and generalizing the solution.\nWeight decay is a pressure on the model, making in generalize because with generalization the model learns to represent more with less.\nComparing such pressure to our own learning, by compressing we create more general understandings. With generalizations we can apply the knowledge to more diverse situations.\nThis blog post discusses their link between compression and good research. Discussing all about how we are compressors. Interesting information upgrades our ability to compress?\nI like this quote from John Baez “Keep synthesizing what you learn into terser, clearer formulations. The goal of learning is not to memorize vast amounts of data. You need to do serious data compression, and filter out the noise.”\nBuilding Fiszka, my spaced repetition application, I\u0026rsquo;m thinking about how to reinforce the compression process. Flash carding doesn\u0026rsquo;t emphasize this aspect of learning, and can even harm it, through over fitting and reliance on cues specific to the card.\nMy application already temporarily rewrites a subset of cards to combat this overfitting, but I need to figure out a way to encourage compression and generalization.\nOf my set of ideas, the simplest one might be best: Ask the user to compress and generalize. Give them a clustered set of cards and prompt them to write simplest explanation possible. Maybe place a limit on words, characters, etc.\n","permalink":"https://www.stkalinow.xyz/posts/valuableconcepts/","summary":"I\u0026rsquo;ve played league for a while, and one particular post on the league subreddit has resonated with me. This post was a translation for a discussion Dopa had on stream after reaching rank one.He discusses his idea of concepts, really just breaking down the game into a set of facts, whoever has the best facts wins. You don\u0026rsquo;t own them, you can take other peoples concepts and refine them.\nI think about this post from time to time.","title":"Thoughts: My most valuable concept."},{"content":"I am a big believer in spaced repetition as a study method. I like it\u0026rsquo;s guaranteed process of learning. By far one of my favorite concepts for flash carding is writing what I call mistake or error cards.\nWhenever I make a mistake or fail at something, I add a card for it. It\u0026rsquo;s usually something along the lines of how a bug was introduced into the code or why I struggled with something I was studying. I try to add cards for even simple and honest mistakes things like forgetting to put a log in a data processing loop.\nI like this concept because it\u0026rsquo;s using my flash carding system (used to be Anki, but now I\u0026rsquo;m writing my own Fiszka) as a guaranteed feedback mechanism. And writing cards for errors feels natural. The errors happened for a reason and I need to reinforce myself to try to avoid it. There have been plenty of time where I learn the solution but still mess up in future occurrences. This is a way to guarantee that I address it, and I don\u0026rsquo;t have to worry about it, I know my program will show and repeat the card if necessary!\nAn important thing to note is that the cards should be structured in a generalized manner. Instead of writing a card like \u0026ldquo;What as the bug introduced in project x?\u0026rdquo;, cards should attack the aspect of why and how the bug occurred. We aren\u0026rsquo;t trying to remember the bug, but think about the general solution.\nAn example if how I had a program simulating a model, and I was using tinkter for the first time. Each frame consisted of a pass through a model and then copy and display it. But it seems I forgot I was running it in a different process, and so the frame was being saved to the local space, and was therefore being cleared right away. I could just write a card \u0026ldquo;What was the bug preventing frames from updating?\u0026rdquo;. But better cards would address the problem. \u0026ldquo;Why did the frames not render?\u0026rdquo;, \u0026ldquo;{Mini example}, What is the bug?\u0026rdquo;, \u0026ldquo;How does the gc in python trigger?\u0026rdquo;. There is nothing wrong with remember a particular moment, but generalized cards are more transferable.\nI think these are my most valuable cards because they come directly from experiences where I do need reminder. They are places I messed up, and adding them guarantees I fix it. It\u0026rsquo;s better than note taking, because my program forces me to address it while notes can be passed over and forgotten. I would recommend any else with a memory practice to pick up the same habit.\n","permalink":"https://www.stkalinow.xyz/posts/bestcards/","summary":"I am a big believer in spaced repetition as a study method. I like it\u0026rsquo;s guaranteed process of learning. By far one of my favorite concepts for flash carding is writing what I call mistake or error cards.\nWhenever I make a mistake or fail at something, I add a card for it. It\u0026rsquo;s usually something along the lines of how a bug was introduced into the code or why I struggled with something I was studying.","title":"Thoughts: My most valuable cards."},{"content":"I am a fan of spaced repetition.\nPlenty of articles have been written advocating it, here is my favorite, Augmenting Long-term Memory by Michael Nielsen\nThe technique is not only let\u0026rsquo;s you choose what to remember, but demonstrates the power of computers. The storage, organization, and scheduling is all handled by these spaced repetition programs. Your only task is to create, pick and choose what goes in.\nPast the benefits, spaced-repetition and flash-carding isn\u0026rsquo;t perfect. The cards created matter. The question of transferring outside the program matters. And the effort + habit needed for the practice.\nI enjoyed this discussion on the adoption of the practice, and why isn\u0026rsquo;t everyone using it. With it\u0026rsquo;s analogy to surfers, it brings up two facets for the practice. There is the technological side, the tools being used. There is the cultural side, the mental habits and concepts in wide spread use.\nFiszka is my technical solution. Experimenting with LLMs, its clear to me and many that this technology could be used to solve some of the problems with the practice of space repetition.\nProblem 1 - Card creation. One of the most natural notions of applying LLMs to the space is the generation of cards.\nCard generation is both difficult and effortful. There is a skill to creating cards, which has to be learned and improved through practice. It\u0026rsquo;s a effortful thing. This effort isn\u0026rsquo;t necessarily a bad thing, the process of creating cards is part of the learning. Thinking how to properly break down and atomize ideas into cards is a teaching process.\nTherefore, although models can write cards, some are arguing against the practice of generating cards, some are extreme enough to call off using any cards but your own.\nWhile I believe its true, that there are benefits to creating your own cards, and the effort of going through it is fruitful.\nUsing pre-written cards is fine.\nIt becomes similar to how tests work. They still provide feedback of what you know and don\u0026rsquo;t know. And are still guaranteed to be learned by being in the system.\nPre-written cards provide their benefit by saving effort \u0026amp; time, as well as in providing a base line quality to cards. Writing cards is a skillfull act. By training a model to write quality cards, beginners get to learn what quality cards look like and the practice becomes more accessible.\nThe generated cards versus writing cards doesn\u0026rsquo;t have to be a mutually exclusive thing, both can be done. Writing cards provides its benefit in the act of thinking and breaking down information into atomic concepts. If you are studying a new domain and just need to memorize the terms right now, get a model to write those cards. Heck, we can generate cards and then write the cards we feel needed added.\nGenerated cards provide benefit of accessibility, saving time, and reducing rote work.\nProblem 2 - Over fitting problem. A problem any practitioner might have ran into, overfitting to cards. When we learn just the answer to cards, and fail to generalize and apply the idea in situations outside the flashcards.\nThis is a major issue. What\u0026rsquo;s the point in learning flash cards if we fail to remember them outside the program.\nNow good high quality cards plays a part in addressing this. It\u0026rsquo;s why modern advice to writing cards involves focusing on the \u0026lsquo;why\u0026rsquo; of ideas. The cards need to try to build up a system and general understanding.\nAnother feature I\u0026rsquo;m adding to address this is card rewriting. Fiszka will take some subset of cards, a provide a temporary rewritten version. Where the version is questioning the same thing. With the card looking different, we need to learn a slightly more general understanding of the idea.\nThis slight jiggling of the range required to know a topic, the card + the range of rewrites, in combination with quality cards should help with instilling a more general understanding of the ideas.\nConclusion There are a range of ideas and features I want to pursue. But, from my experience, it\u0026rsquo;s better to start simple and let things grow. One day I will explore simulations, shared learning, and automatic coaching. But for now, I just plan on keeping it simple and focusing on addressing my main two problems with space repetition.\n","permalink":"https://www.stkalinow.xyz/posts/projectfiszka/","summary":"I am a fan of spaced repetition.\nPlenty of articles have been written advocating it, here is my favorite, Augmenting Long-term Memory by Michael Nielsen\nThe technique is not only let\u0026rsquo;s you choose what to remember, but demonstrates the power of computers. The storage, organization, and scheduling is all handled by these spaced repetition programs. Your only task is to create, pick and choose what goes in.\nPast the benefits, spaced-repetition and flash-carding isn\u0026rsquo;t perfect.","title":"Project: Fiszka"},{"content":"I was reading through this CodeT5 paper, and this plain sight idea struck me; for encoder-decoder models, why aren\u0026rsquo;t we prompting with a separate decoder part? Like we have our input prompt to the encoder, but we could also add another part of the prompt to be used in the decoder.\nIt might be mentioned somewhere, but I couldn\u0026rsquo;t find anything.\nIn prompting, we are trying to influence the output of the model. This influence is seen not only in the text we write, but the form we write it in. For encoder-decoder models, its just makes sense to keep the core of the ideas in the encoder input, and any meta-structure (ex. Summary:, ```JSON, \u0026ldquo;The key ideas of the text are \u0026hellip;\u0026rdquo;, etc) should only go into the decoder part.\nSo, make the encoded section represent the ideas and the task.\nWhile the decoder receives some starting template to influence the generation.\nYou wouldn\u0026rsquo;t want to always do this. It works main for tasks which have a natural shape/starting point. So, for a outline generation task: Encoder input is \u0026ldquo;Create an outline for the following story. {story_traits}\u0026rdquo; Decoder input is \u0026ldquo;Outline:\\n Beginning: \u0026quot; Here we are giving the model a starting text to begin generating from! But it isn\u0026rsquo;t muddying the encoding part!\nHere is a link to my notebook doing this with HuggingFace using t5-flan.\nIt\u0026rsquo;s not a complete end-all be-all solution, but this would have been such a useful trick for me had I thought of it earlier.\nExample results:\nFirst keep in mind. These where generated using flan-t5-large, which is just a bit under 1B params! flan-t5 also isn\u0026rsquo;t trained on code data as far as I know, which means strictness of formatting isn\u0026rsquo;t as strong.\nWe can see above how our starting prompt of \u0026ldquo;Outline:\\n Beginning:\u0026rdquo; funnels the generation, giving a frame work.\nThe above example shows both the training bias and how our decoder input can have a negative influence!\nSo hopefully this gives some idea on the technique of adding input strictly to the decoder. Gives us an avenue to influence the generation, but we need to be carefully test them out. I also suspect it to be more useful for models tuned on code because of the logic and formatting of the medium can be utilized!\n","permalink":"https://www.stkalinow.xyz/posts/experimentencoderdecodergeneration/","summary":"I was reading through this CodeT5 paper, and this plain sight idea struck me; for encoder-decoder models, why aren\u0026rsquo;t we prompting with a separate decoder part? Like we have our input prompt to the encoder, but we could also add another part of the prompt to be used in the decoder.\nIt might be mentioned somewhere, but I couldn\u0026rsquo;t find anything.\nIn prompting, we are trying to influence the output of the model.","title":"Experiment: Encoder-Decoder Generation"},{"content":"I read this great write up by Krzysztof Kowalczyk about their experience writing SumatraPDF. One of their focuses was on simple design, with “80% of functionality with 20% of the UI.”\nNote taking, with pen and paper, follows this rule, if not more so. Its ink on paper, but the possibilities are endless! We create our own writing and note taking system, system of marking, staring, and highlighting. The act of writing is simple, but the expressive ness is high.\nBut this idea only focuses on accessibility, make users immediately do what they want.\nGame design has an idea of skill floor and skill ceiling. Skill floor focuses on entry level players, ones just starting. Having a low skill floor means its easy for anyone to pick up and play the game. A high skill floor means players need to learn much more before they can grasp the game. This 80/20 UI rule centres around creating a low skill floor, make it easy for new users to use the app.\nBut there is the idea of skill ceiling, how much can possibly be done/expressed. Games with high skill ceiling means players have a lot to learn before they truly mastered the game. In the context of apps and UI, a high skill ceiling means the user can do a lot with the tool. Think of drawing or animating tools, they provide many options and functionality, which means there is much to master.\nPreferably, game devs aim for the combination of both a low skill floor and high skill ceiling. “Easy to learn, hard to master”\nPen \u0026amp; paper follows this paradigm. Its easy to draw and take note, and there is plenty of room for expression and mastery.\nThinking about designs in my own applications. I wrote about fluid designs before, and how LLMs can create dynamic interfaces for users, custom. I also wrote about how applications designed around LLMs need to be correctable, because they are making some level of assumptions.\nSo I should design around easy to use parts, giving only a core set of options. But these options should allow for a degree of expression. For my flash card application I\u0026rsquo;m working on, it generates cards using LLMs, I guess I should focus on creating a core set of generation blocks the user can use, and let the user create their complexity by combining these blocks.\n","permalink":"https://www.stkalinow.xyz/posts/thoughtstoolsskillceiling/","summary":"I read this great write up by Krzysztof Kowalczyk about their experience writing SumatraPDF. One of their focuses was on simple design, with “80% of functionality with 20% of the UI.”\nNote taking, with pen and paper, follows this rule, if not more so. Its ink on paper, but the possibilities are endless! We create our own writing and note taking system, system of marking, staring, and highlighting. The act of writing is simple, but the expressive ness is high.","title":"Thoughts: Tools \u0026 Skill Ceiling"},{"content":"I create a simple web page to score sentences based on input traits.\nThe idea is to let the models to take care of all the hard stuff, while we are just left with connecting everything up.\nIn this case we are creating a page similar to my Lenses project, but now the model does the heavy lifting.\nIt will take in some input text, a set of traits, and the output would be scores for each sentence.\nWe pass these inputs to the model, and it does all the parsing and scoring in one go. Done.\nIt\u0026rsquo;s far from a perfect implementation. I didn\u0026rsquo;t even experiment that much with the prompt either.\nWe could improve our prompt, make it multi pass, do chain of thought, etc.\nBut this isn\u0026rsquo;t the point of the experiment, its just to show the idea of this delegation idea.\nThere is the general language task of ranking the sentences, which language models let the computer do. But there is also the difficult task of parsing natural language. We don\u0026rsquo;t fret over rules, the model just understands what is a sentence and isn\u0026rsquo;t, from vibes!\nSo currently this crude implementation isn\u0026rsquo;t cleanly working, but its shows this idea. I created this pretty quickly, slamming components together, a single query, done.\nI still think anything consistent will require hard coded programs, but anything with a little wiggle room can build on this idea.\nLink to the repo: https://github.com/STKalinowski/Scores\nI built it on replit because I wanted to see how that platform was doing, so here\u0026rsquo;s the replit link.\nReplit Link: https://replit.com/@StasKalinowski/SimpleScores?v=1\n","permalink":"https://www.stkalinow.xyz/posts/experimentscores/","summary":"I create a simple web page to score sentences based on input traits.\nThe idea is to let the models to take care of all the hard stuff, while we are just left with connecting everything up.\nIn this case we are creating a page similar to my Lenses project, but now the model does the heavy lifting.\nIt will take in some input text, a set of traits, and the output would be scores for each sentence.","title":"Experiment: Scores"},{"content":"Computers can now understand our language, how can we apply this to processes. One of the ideas is viewing text as a map. Normal reading, Top to Bottom \u0026amp; Right to Left. Maps, visually display information which is immediately recognizable, zoom in and out.\nThis map like approach is what I\u0026rsquo;m going for in Lenses.\nFirst the application begins by bringing in the text you\u0026rsquo;re reading, you can paste it in or provide a link and it will try its best to get the relevant text.\nThen once we have the text displayed there are two main features:\nLens Views \u0026amp; Map Summary.\nLens Views:\nIn Lenses you are allowed to create labels. Then when selected, the labels will highlight the main text based on how related the text is to the labels. So text more related is a darker red while text less related is lighter. This allows you to visually pick up on the relevant parts, if your mainly interested in one specific idea, you can scroll through and visually pick up on the parts. Additionally, you can have multiple lenses selected at once. So if you have a range of ideas you want to focus on, just add them.\nNow lets say while reading, a particular idea in the text strikes you and you want to focus on it, well all the sentences in the text are selectable lenses! So, if you\u0026rsquo;re in an abstract and see some relevant ideas, you can pick them out and go to the ones you want!\nBut lenses can be a bit more dynamic. One idea I found in testing was using lenses to cross off ideas. As we learn about ideas, anything we know we add to our pool of lenses and we focus on the parts which are less highlighted!\nMap Summary:\nThe ability to zoom in and out. You can create summaries of the main text and each sentence in the summary is selectable! If an idea in the summary stands out, you can click on it and be taken to the related section in the text. So it acts as a zoomed out version and you can zoom in with the summary.\nThat\u0026rsquo;s lenses, exploring the idea of non-linear reading. I mainly made it because there are just too many ML papers to read and I\u0026rsquo;ve been making tools to help me process this information much faster. Originally I was justing going to make lenses based on my notes, but I found this custom label creation to feel much better. The best feature is definitely the lens from the text, being able to pick a sentence from the text and focusing on that specific part of the paper is a godsend. Right now I still need to improve inference speed and better text processing for relevant text, specifically with pdfs. Once I work those things out and do a bit of refactoring I\u0026rsquo;ll release the code.\n","permalink":"https://www.stkalinow.xyz/posts/projectlenses/","summary":"Computers can now understand our language, how can we apply this to processes. One of the ideas is viewing text as a map. Normal reading, Top to Bottom \u0026amp; Right to Left. Maps, visually display information which is immediately recognizable, zoom in and out.\nThis map like approach is what I\u0026rsquo;m going for in Lenses.\nFirst the application begins by bringing in the text you\u0026rsquo;re reading, you can paste it in or provide a link and it will try its best to get the relevant text.","title":"Project: Lenses"},{"content":"I\u0026rsquo;ve been tinkering with LLMs and they\u0026rsquo;re cool because we can ask them stuff in plain english and they respond accordingly! But the real sorcery begins when we ask them to reason, and they can do this! We\u0026rsquo;ve got computers to \u0026ldquo;think\u0026rdquo;, we\u0026rsquo;ve invented magic!\nNow, I understand, it\u0026rsquo;s not real magic, they aren\u0026rsquo;t doing real reasoning. It\u0026rsquo;s an imitation, through the use of statistics and the process of predicting the next word. But I don\u0026rsquo;t think it matters.\nI like to view their capabilities of the models like a movie set. While on set, we\u0026rsquo;re in the Wild West! But, as we start walking to the edge, it\u0026rsquo;s clearly not the main street, turns out, we\u0026rsquo;re in a parking lot. For language models, they have a constructed movie set of their own where we can act \u0026amp; do scenes in. As long as we remain on set, our shots will appear believable. For language models, their movie set is constructed from their training data, and shooting scenes are the prompts we give the model. The closer we keep our prompt to the training data, the mode believable and on set we will be. So asking the model to give writing feedback will go great because the model has likely seen something of the sort. Asking a model to program in a new programming language it has never scene is going to perform poorly because it hasn\u0026rsquo;t been trained to do this.\nLuckily, the training data for these large language models is so immense and the parameter count so large, that we effectively get a reasoning engine. Effectively in the sense of, most reasonable things you can ask it to do are likely to fall somewhere in the training data.\nWhether the language models have true reasoning or not, it does not matter. In the end, if the output is close enough, then we can put their abilities to work.\nNow, when putting large language models to work, we can use them to do informational work for us, but the real dark arts lies in their use as reasoning engines. What we can do is connect programs together with LLMs. The models will act as reasoning engines, where they receive input, are prompted to reason and \u0026ldquo;think\u0026rdquo; about the input, and then make decisions appropriately. We can use them as a connective tissue. This idea is in the vein off Software 2.0, where we let the model and the data design the behavior. Where we worry less about the complexity and variety of situations, because we rely on the model to make reasonable decisions based on the input.\nWe can apply the idea to act between programs, processing and formatting the inputs and outputs. Or we can take steps to make it handle more and more tasks, having it think about the order of operations and which functions to call. On the extreme end is having the model act as the sole entity of the program itself, one of the earlier interesting experiments of GPT3 was having it pretend to be a backend server. This is a bit extreme, and the better applications are in domains with high variance or variability, so think things like level generation, creating suggestions for users, or working with user input.\nUser input is the application of LLMs which fascinates me the most because it lets us relax the interfaces we need. Computers always require such structured formatting with their input forms and structure, but by using language models, we can relax these requirements.\nThere was this great article discussing chat bots and interfaces, I would recommend. It highlights the benefits of chat bots, with them giving an pure open text-box, users are allowed to structure their input in the way they want. This allows them to use these chat bots dynamically, one moment asking for ideas with the next asking for feedback. But the article highlights the problem with this freedom, blank text-boxes don\u0026rsquo;t give any structure, they don\u0026rsquo;t tell the user how to use them, and they require constant work of typing out the context.\nBut here is where we can apply the dark arts, language models can solve their own problems! They be used to provide structure for the user, by giving suggestion prompts or generating interfaces, like buttons \u0026amp; sliders, dynamically. This can be done because we can feed the context where the language model can reason about the current desires of the user. We can reduce the work of the user by creating systems which automatically feed the model the context, where the application reaches a level of point and understand.\nGitHub Copilot is an example of automatically providing context. It\u0026rsquo;s a code generation application which automatically looks at surrounding text and accompanying files when generating code suggestions. The user doesn\u0026rsquo;t have the burden of inputing all the relevant parts of their code.\nWordcraft is an example of prompt suggestion. They ran a study with a set of writers and their demo writing app Wordcraft. The application doesn\u0026rsquo;t just generate text with language models, but it also creates suggestion prompts based on what is currently written. These auto generated prompts match the situation and can help give structure plus reduce work.\nWhere I see programs headed, they are going to augmented with these language models, creating dynamic programs. Where we can use them for interfaces like I\u0026rsquo;ve discussed or for even between programs. The models can reason about what to query. the format, or reason about results of functions. We can break from the rigidity of hard coded programs and insert the reasoning engines to create flexible ones.\nLets pause and discuss note-taking. Given a piece of paper, everyone has their own system of notes, and it changes depending on the task. At one moment we could be writing a web of ideas, drawing diagrams and pictures. In the next we could be diligently noting down everything the lecturer is say, starting the bits we don\u0026rsquo;t understand. Notes \u0026amp; paper are dynamic, they fit into our form of thinking.\nI see a form of programs where the interfaces are dynamic, where the programs are dynamic, where the software adapts to the our mode of thinking and needs, mirroring the fluidity of pen and paper. Just as our note-taking shifts to accommodate varying tasks, we could have our software morph and modify in real-time to better fit our needs. I imagine a future where software is not a rigid predefined tool, but a flexible partner in our process.\nLLMs can help enable these fluid programs, through thinking and adapting about our situation and desires. The future of software could consist of two thing, a model and a database, and everything else is generated.\nCurrently, these fluid systems aren\u0026rsquo;t completely practical. The models aren\u0026rsquo;t THAT smart. Inference takes too long. Compute power, especially on the edge, is limited. But we are in those early days of technology, and we don\u0026rsquo;t know the limits \u0026amp; feasibilities yet. The glimpses are there, the road ahead looks promising, there is plenty of room, let\u0026rsquo;s be positive and keep moving.\n","permalink":"https://www.stkalinow.xyz/posts/darkartsofllms/","summary":"I\u0026rsquo;ve been tinkering with LLMs and they\u0026rsquo;re cool because we can ask them stuff in plain english and they respond accordingly! But the real sorcery begins when we ask them to reason, and they can do this! We\u0026rsquo;ve got computers to \u0026ldquo;think\u0026rdquo;, we\u0026rsquo;ve invented magic!\nNow, I understand, it\u0026rsquo;s not real magic, they aren\u0026rsquo;t doing real reasoning. It\u0026rsquo;s an imitation, through the use of statistics and the process of predicting the next word.","title":"Thoughts: Dark Arts of Language Models"},{"content":"While working on my D\u0026amp;D application, I\u0026rsquo;ve been thinking about designing around language models. I\u0026rsquo;ve come to the conclusion that any application using language models should design around correcting them.\nI was trying hard to make my “DM” as correct as possible. Wrangling the prompts, contexts, and pipelines, and I realized, we can\u0026rsquo;t guarantee perfect information.\nCommunication is a hard thing we even struggle doing between people. Who hasn\u0026rsquo;t misunderstood someone or needed clarification. Watching D\u0026amp;D play throughs confirmed this for me, there are plenty moments of clarification and correction.\nLanguage is just ambiguous, we make assumptions and stamens we think are concrete are actually vague without our internal context. Sure, we can improve our model \u0026amp; systems to automatically grab such context, but there is just a natural vagueness in language. I\u0026rsquo;m sure we\u0026rsquo;ve all had the phenomenon of a perfect image in our head, but putting it on paper just doesn\u0026rsquo;t reflect our ideas.\n“The only writers who have any peace are the ones who don\u0026rsquo;t write. And there are some like that. They wallow in a sea of possibilities. To express a thought, you first have to limit it, and that means kill it. Every word I speak robs me of a thousand others, and every line I write means giving up another.” - Stanislaw Lem, Hospital of the Transfiguration\nIf we want to instil such strict level of specificity, we actually have a system for this, its called programming. But, the benefit of using language models is that they can work with language, they reduce the need for such a level of specificity.\nTherefore, I think when designing applications around language mode, there will naturally be incorrect outputs, and the focus should be on making the process of correcting them seamless. The model will get something wrong, make it easy for the user to correct it.\n","permalink":"https://www.stkalinow.xyz/posts/designforerrors/","summary":"While working on my D\u0026amp;D application, I\u0026rsquo;ve been thinking about designing around language models. I\u0026rsquo;ve come to the conclusion that any application using language models should design around correcting them.\nI was trying hard to make my “DM” as correct as possible. Wrangling the prompts, contexts, and pipelines, and I realized, we can\u0026rsquo;t guarantee perfect information.\nCommunication is a hard thing we even struggle doing between people. Who hasn\u0026rsquo;t misunderstood someone or needed clarification.","title":"Thoughts: Design for errors."},{"content":"While learning how to write watching Brandon Snaderson\u0026rsquo;s Lectures, I came across the idea of the \u0026ldquo;abstract pyramid\u0026rdquo;. I believe it encapsulates the whole idea of prompting,(Prompting in the sense of language models.)\nMentioned in lecture 8 on world building, the pyramid of abstraction is about the ambiguity of a piece of writing. It\u0026rsquo;s focus is on the variety of interpretations a reader can have. Anytime we write something the piece of writing has a natural range of interpretations, not all readers see the exact same thing.\nIf we write just “A door.” and there are a wide variety of doors people can imagine. Big doors, old doors, red doors, blue doors. This piece of writing is abstract and the number of interpretations is high. But if we write “An old brown door”, then the ranges begin to collapse. By adding descriptions, we narrow down the possible interpretations people will naturally have.\nContext helps, “For the old cabin deep in the forest, they stood in front of the door.”, the readers can infer the look of the door based of everything. Context is important because it helps reduce work and focus on the important bits of communication. By saying a old cabin in the woods, a image of a wooden worn down cabin appears. We now just need to spend effort detailing anything necessary, key plot elements: \u0026ldquo;An axe slanted beside the door\u0026rdquo;, anything out of distribution: \u0026ldquo;Rays of gold and purple shone out from the door windows\u0026rdquo;.\n(Rewrite) The non-normal portion was the point of Brandon\u0026rsquo;s lecture, it\u0026rsquo;s where we have opportunity to leave in world building. But this aspect highlights the fact that writers rely on the context of their audience. Most people have a sense of what a modern day old cabin in the woods looks like, the range is narrow. But asked to imagine a house in 1660 Sweden will be less familiar, and a wider range(maybe narrower, where readers converge to common stereo types). And this is why in my communications class we spent so much time discussing the backgrounds of text, especially for older ones. Writers make assumptions about their readers and their interpretations.\nTherefore the abstract pyramid is about the range of interpretations, with both a focus on the words used and the background of the reader. The goal of the writer isn\u0026rsquo;t to never to have one interpretation, it\u0026rsquo;s impossible, but narrow the interpretation to a good enough range.\nUpon hearing the concept, the link to prompting language models was apparent. Prompting is about narrowing the interpretation, involving both the words used and the background information. People have a background context of what they know, the equivalent in models is their training data. Our goal with prompting is the same as with writing, narrow the range of interpretations into the desired area.\nPrompting models is different than writing for people. Not only is their understanding of the world different, there is a meta structural factor to prompting. The physical layout/structure plays a role in the interpretation.\nTo demonstrate how model interpretations work, lets take the pyramid of abstraction to its extreme. If we prompt a model, and give it as much details as possible, leaving no room for missinterpretation, are we going to find a perfect response? No.\nThe problem here is that the models interpretation is grounded in its training data. Think about the intructions we usually receive, they aren\u0026rsquo;t as long and strict, most are contain a heavy amount of implications. (There is a domain which does contain less ambiguity, programming!).\nData plays an important part for interpretation, so think about your models training and fine-tuning data. If you\u0026rsquo;re working with a base mode, structure plays an important role, leave hints in the formatting of your prompt. If you\u0026rsquo;re working with a instruction tuned model, then it\u0026rsquo;s biased to interpreting the input as instructions. If you\u0026rsquo;re creating a finetune dataset, think about it in reverse, how should the model be interpreting input.\nI\u0026rsquo;ve found this abstraction pyramid to be a valuable tool in crafting prompts. It\u0026rsquo;s something I was doing already, just hadn\u0026rsquo;t conceptualized and put a name to it till now.\n","permalink":"https://www.stkalinow.xyz/posts/promptingwriting/","summary":"While learning how to write watching Brandon Snaderson\u0026rsquo;s Lectures, I came across the idea of the \u0026ldquo;abstract pyramid\u0026rdquo;. I believe it encapsulates the whole idea of prompting,(Prompting in the sense of language models.)\nMentioned in lecture 8 on world building, the pyramid of abstraction is about the ambiguity of a piece of writing. It\u0026rsquo;s focus is on the variety of interpretations a reader can have. Anytime we write something the piece of writing has a natural range of interpretations, not all readers see the exact same thing.","title":"Thoughts: Is prompting just writing?"}]