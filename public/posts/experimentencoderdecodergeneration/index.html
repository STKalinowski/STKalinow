<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Experiment: Encoder-Decoder Generation | STKalinow</title>
<meta name="keywords" content="">
<meta name="description" content="Better encoder-decoder generation with one simple change">
<meta name="author" content="Stanislaw Kalinowski">
<link rel="canonical" href="https://www.stkalinow.xyz/posts/experimentencoderdecodergeneration/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://www.stkalinow.xyz/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.stkalinow.xyz/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.stkalinow.xyz/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.stkalinow.xyz/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.stkalinow.xyz/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Experiment: Encoder-Decoder Generation" />
<meta property="og:description" content="Better encoder-decoder generation with one simple change" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.stkalinow.xyz/posts/experimentencoderdecodergeneration/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-07-07T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Experiment: Encoder-Decoder Generation"/>
<meta name="twitter:description" content="Better encoder-decoder generation with one simple change"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://www.stkalinow.xyz/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Experiment: Encoder-Decoder Generation",
      "item": "https://www.stkalinow.xyz/posts/experimentencoderdecodergeneration/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Experiment: Encoder-Decoder Generation",
  "name": "Experiment: Encoder-Decoder Generation",
  "description": "Better encoder-decoder generation with one simple change",
  "keywords": [
    
  ],
  "articleBody": "I was reading through this CodeT5 paper, and this plain sight idea struck me; for encoder-decoder models, why aren’t we prompting with a separate decoder part? Like we have our input prompt to the encoder, but we could also add another part of the prompt to be used in the decoder.\nIt might be mentioned somewhere, but I couldn’t find anything.\nIn prompting, we are trying to influence the output of the model. This influence is seen not only in the text we write, but the form we write it in. For encoder-decoder models, its just makes sense to keep the core of the ideas in the encoder input, and any meta-structure (ex. Summary:, ```JSON, “The key ideas of the text are …”, etc) should only go into the decoder part.\nSo, make the encoded section represent the ideas and the task.\nWhile the decoder receives some starting template to influence the generation.\nYou wouldn’t want to always do this. It works main for tasks which have a natural shape/starting point. So, for a outline generation task: Encoder input is “Create an outline for the following story. {story_traits}” Decoder input is “Outline:\\n Beginning: \" Here we are giving the model a starting text to begin generating from! But it isn’t muddying the encoding part!\nHere is a link to my notebook doing this with HuggingFace using t5-flan.\nIt’s not a complete end-all be-all solution, but this would have been such a useful trick for me had I thought of it earlier.\nExample results:\nFirst keep in mind. These where generated using flan-t5-large, which is just a bit under 1B params! flan-t5 also isn’t trained on code data as far as I know, which means strictness of formatting isn’t as strong.\nWe can see above how our starting prompt of “Outline:\\n Beginning:” funnels the generation, giving a frame work.\nThe above example shows both the training bias and how our decoder input can have a negative influence!\nSo hopefully this gives some idea on the technique of adding input strictly to the decoder. Gives us an avenue to influence the generation, but we need to be carefully test them out. I also suspect it to be more useful for models tuned on code because of the logic and formatting of the medium can be utilized!\n",
  "wordCount" : "384",
  "inLanguage": "en",
  "datePublished": "2023-07-07T00:00:00Z",
  "dateModified": "2023-07-07T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Stanislaw Kalinowski"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.stkalinow.xyz/posts/experimentencoderdecodergeneration/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "STKalinow",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.stkalinow.xyz/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.stkalinow.xyz" accesskey="h" title="STKalinow (Alt + H)">STKalinow</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.stkalinow.xyz/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://www.stkalinow.xyz/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Experiment: Encoder-Decoder Generation
    </h1>
    <div class="post-description">
      Better encoder-decoder generation with one simple change
    </div>
    <div class="post-meta"><span title='2023-07-07 00:00:00 +0000 UTC'>July 7, 2023</span>&nbsp;·&nbsp;Stanislaw Kalinowski

</div>
  </header> 
  <div class="post-content"><p>I was reading through this <a href="https://github.com/salesforce/CodeT5">CodeT5 paper</a>, and this plain sight idea struck me; for encoder-decoder models, why aren&rsquo;t we prompting with a separate decoder part? Like we have our input prompt to the encoder, but we could also add another part of the prompt to be used in the decoder.</p>
<p>It might be mentioned somewhere, but I couldn&rsquo;t find anything.</p>
<p>In prompting, we are trying to influence the output of the model. This influence is seen not only in the text we write, but the form we write it in. For encoder-decoder models, its just makes sense to keep the core of the ideas in the encoder input, and any meta-structure (ex. Summary:, ```JSON, &ldquo;The key ideas of the text are &hellip;&rdquo;, etc) should only go into the decoder part.</p>
<p>So, make the encoded section represent the ideas and the task.</p>
<p>While the decoder receives some starting template to influence the generation.</p>
<p>You wouldn&rsquo;t want to always do this. It works main for tasks which have a natural shape/starting point. So, for a outline generation task:
Encoder input is &ldquo;Create an outline for the following story. {story_traits}&rdquo;
Decoder input is &ldquo;Outline:\n Beginning: &quot;
Here we are giving the model a starting text to begin generating from! But it isn&rsquo;t muddying the encoding part!</p>
<p><a href="https://github.com/STKalinowski/EncoderDecoderModelBetterGen">Here is a link to my notebook doing this with HuggingFace using t5-flan.</a></p>
<p>It&rsquo;s not a complete end-all be-all solution, but this would have been such a useful trick for me had I thought of it earlier.</p>
<p>Example results:</p>
<p>First keep in mind. These where generated using flan-t5-large, which is just a bit under 1B params! flan-t5 also isn&rsquo;t trained on code data as far as I know, which means strictness of formatting isn&rsquo;t as strong.</p>
<p><img loading="lazy" src="/images/EncoderDecoder/WriteOutline.png" alt="WriteOutline.PNG"  />
</p>
<p>We can see above how our starting prompt of &ldquo;Outline:\n Beginning:&rdquo; funnels the generation, giving a frame work.</p>
<p><img loading="lazy" src="/images/EncoderDecoder/GenuineOutput.png" alt="GenuineOutput.PNG"  />
</p>
<p><img loading="lazy" src="/images/EncoderDecoder/GenuineOutput2.png" alt="GenuineOutput2.PNG"  />
</p>
<p><img loading="lazy" src="/images/EncoderDecoder/BadQA.png" alt="BadQA.PNG"  />
</p>
<p>The above example shows both the training bias and how our decoder input can have a negative influence!</p>
<p><img loading="lazy" src="/images/EncoderDecoder/QA.png" alt="QA.PNG"  />
</p>
<p><img loading="lazy" src="/images/EncoderDecoder/WritingInf.png" alt="WritingInf.PNG"  />
</p>
<p><img loading="lazy" src="/images/EncoderDecoder/WritingInf2.png" alt="WritingInf2.PNG"  />
</p>
<p><img loading="lazy" src="/images/EncoderDecoder/Bob1.png" alt="Bob1.PNG"  />
</p>
<p><img loading="lazy" src="/images/EncoderDecoder/Bob2.png" alt="Bob2.PNG"  />
</p>
<p>So hopefully this gives some idea on the technique of adding input strictly to the decoder. Gives us an avenue to influence the generation, but we need to be carefully test them out. I also suspect it to be more useful for models tuned on code because of the logic and formatting of the medium can be utilized!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://www.stkalinow.xyz">STKalinow</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <script defer src="/_vercel/insights/script.js"></script>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
